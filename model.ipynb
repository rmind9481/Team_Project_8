{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [이미지 불러와서 데이터 셋 저장]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반적인 포멧의 이미지 처리 모듈\n",
    "import cv2\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "# 이미지 데이터가 저장된 타입 관련 모듈\n",
    "import numpy as np\n",
    "# 폴더, 파일, 경로 관련 모듈\n",
    "import os \n",
    "\n",
    "import koreanize_matplotlib\n",
    "\n",
    "import joblib  # 모델 저장용\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. HOG 특징 추출 함수\n",
    "def extract_hog_features(img, img_size=(128, 128)):\n",
    "    img = cv2.resize(img, img_size)\n",
    "    features, _ = hog(img, orientations=9, pixels_per_cell=(8, 8),\n",
    "                      cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')\n",
    "    return features\n",
    "\n",
    "# 2. 이미지 불러오기 + 라벨링\n",
    "def load_target_and_others(target_dir='./data/image/gray', others_dir='./data/image/gray_others'):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # 타겟 이미지 (label = 1)\n",
    "    for file in os.listdir(target_dir):\n",
    "        if file.lower().endswith(('.jpg', '.png','.jpeg')):\n",
    "            path = os.path.join(target_dir, file)\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                features = extract_hog_features(img)\n",
    "                X.append(features)\n",
    "                y.append(1)\n",
    "\n",
    "    # Others 이미지 (label = 0)\n",
    "    for file in os.listdir(others_dir):\n",
    "        if file.lower().endswith(('.jpg', '.png')):\n",
    "            path = os.path.join(others_dir, file)\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                features = extract_hog_features(img)\n",
    "                X.append(features)\n",
    "                y.append(0)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 3. 데이터 로딩 및 전처리\n",
    "X, y = load_target_and_others()\n",
    "\n",
    "# 4. 학습/테스트 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# # 5. 모델 학습\n",
    "# scv_model = SVC(kernel='linear', probability=True)\n",
    "# scv_model.fit(X_train, y_train)\n",
    "\n",
    "# # 6. 예측 및 평가\n",
    "# y_pred = scv_model.predict(X_test)\n",
    "# print(\"✅ 정확도:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"📊 분류 리포트:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_on_image(image_path, model, target_name=\"Target\"):\n",
    "    # 1. 얼굴 검출기\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # 2. 이미지 읽기\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(\"❌ 이미지 로딩 실패\")\n",
    "        return\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 3. 얼굴 검출\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "    print(f\"🔍 감지된 얼굴 수: {len(faces)}\")\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_img = gray[y:y+h, x:x+w]\n",
    "        features = extract_hog_features(face_img)\n",
    "\n",
    "        # 4. 예측\n",
    "        prediction = model.predict([features])[0]\n",
    "        label = target_name if prediction == 1 else \"Others\"\n",
    "\n",
    "        # 5. 결과 시각화\n",
    "        color = (0, 255, 0) if prediction == 1 else (0, 0, 255)\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(img, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "    # 6. 결과 보기\n",
    "    cv2.imshow(\"검증 결과\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_model_on_image('./test/IMG_4736.jpg', scv_, target_name=\"Karina\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\"):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n📌 [{model_name}] 평가 결과\")\n",
    "    print(f\"✅ 정확도: {acc:.4f}\")\n",
    "    print(\"📊 분류 리포트:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_model_random_forest(X_train, y_train, X_test, y_test):\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_model(model, X_test, y_test, \"Random Forest\")\n",
    "    return model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train_model_logistic(X_train, y_train, X_test, y_test):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_model(model, X_test, y_test, \"Logistic Regression\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# 1. SVC (선형)\n",
    "def train_model_svc_linear(X_train, y_train, X_test, y_test):\n",
    "    model = SVC(kernel='linear', probability=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_model(model, X_test, y_test, \"SVC (linear)\")\n",
    "    return model\n",
    "\n",
    "# 2. SVC (RBF)\n",
    "def train_model_svc_rbf(X_train, y_train, X_test, y_test):\n",
    "    model = SVC(kernel='rbf', probability=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_model(model, X_test, y_test, \"SVC (RBF)\")\n",
    "    return model\n",
    "\n",
    "# 3. Random Forest\n",
    "def train_model_random_forest(X_train, y_train, X_test, y_test):\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_model(model, X_test, y_test, \"Random Forest\")\n",
    "    return model\n",
    "\n",
    "# 4. Decision Tree\n",
    "def train_model_decision_tree(X_train, y_train, X_test, y_test):\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_model(model, X_test, y_test, \"Decision Tree\")\n",
    "    return model\n",
    "\n",
    "# 5. Logistic Regression\n",
    "def train_model_logistic(X_train, y_train, X_test, y_test):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_model(model, X_test, y_test, \"Logistic Regression\")\n",
    "    return model\n",
    "\n",
    "# 6. KNN\n",
    "def train_model_knn(X_train, y_train, X_test, y_test):\n",
    "    model = KNeighborsClassifier(n_neighbors=3)\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_model(model, X_test, y_test, \"KNN\")\n",
    "    return model\n",
    "\n",
    "# 7. Naive Bayes\n",
    "def train_model_naive_bayes(X_train, y_train, X_test, y_test):\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_model(model, X_test, y_test, \"Naive Bayes\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 [Random Forest] 평가 결과\n",
      "✅ 정확도: 0.7570\n",
      "📊 분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77       288\n",
      "           1       0.78      0.71      0.74       280\n",
      "\n",
      "    accuracy                           0.76       568\n",
      "   macro avg       0.76      0.76      0.76       568\n",
      "weighted avg       0.76      0.76      0.76       568\n",
      "\n",
      "\n",
      "📌 [KNN] 평가 결과\n",
      "✅ 정확도: 0.7113\n",
      "📊 분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.63      0.69       288\n",
      "           1       0.68      0.79      0.73       280\n",
      "\n",
      "    accuracy                           0.71       568\n",
      "   macro avg       0.72      0.71      0.71       568\n",
      "weighted avg       0.72      0.71      0.71       568\n",
      "\n",
      "\n",
      "📌 [SVC (linear)] 평가 결과\n",
      "✅ 정확도: 0.8451\n",
      "📊 분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85       288\n",
      "           1       0.84      0.85      0.84       280\n",
      "\n",
      "    accuracy                           0.85       568\n",
      "   macro avg       0.85      0.85      0.85       568\n",
      "weighted avg       0.85      0.85      0.85       568\n",
      "\n",
      "\n",
      "📌 [SVC (RBF)] 평가 결과\n",
      "✅ 정확도: 0.8891\n",
      "📊 분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       288\n",
      "           1       0.88      0.89      0.89       280\n",
      "\n",
      "    accuracy                           0.89       568\n",
      "   macro avg       0.89      0.89      0.89       568\n",
      "weighted avg       0.89      0.89      0.89       568\n",
      "\n",
      "\n",
      "📌 [Decision Tree] 평가 결과\n",
      "✅ 정확도: 0.6180\n",
      "📊 분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63       288\n",
      "           1       0.62      0.60      0.61       280\n",
      "\n",
      "    accuracy                           0.62       568\n",
      "   macro avg       0.62      0.62      0.62       568\n",
      "weighted avg       0.62      0.62      0.62       568\n",
      "\n",
      "\n",
      "📌 [Logistic Regression] 평가 결과\n",
      "✅ 정확도: 0.8644\n",
      "📊 분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87       288\n",
      "           1       0.86      0.87      0.86       280\n",
      "\n",
      "    accuracy                           0.86       568\n",
      "   macro avg       0.86      0.86      0.86       568\n",
      "weighted avg       0.86      0.86      0.86       568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 예시: 랜덤 포레스트 모델 학습 및 평가\n",
    "rf_model = train_model_random_forest(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# 예시: KNN 모델 학습 및 평가\n",
    "knn_model = train_model_knn(X_train, y_train, X_test, y_test)\n",
    "\n",
    "scv_lr_model = train_model_svc_linear(X_train,y_train, X_test,y_test)\n",
    "\n",
    "scv_RBF_model = train_model_svc_rbf(X_train,y_train, X_test,y_test)\n",
    "\n",
    "dt_model = train_model_decision_tree(X_train,y_train, X_test,y_test)\n",
    "\n",
    "log_model = train_model_logistic(X_train,y_train, X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 감지된 얼굴 수: 4\n"
     ]
    }
   ],
   "source": [
    "test_model_on_image('./test/IMG_4728.jpg', knn_model, target_name=\"Karina\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델 저장 완료: model.pkl\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(scv_RBF_model, 'model.pkl')\n",
    "print(\"✅ 모델 저장 완료: model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVC_liner\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43maccuracy_score\u001b[49m(y_test, scv_lr_model\u001b[38;5;241m.\u001b[39mpredict(X_test)),\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m: accuracy_score(y_test, rf_model\u001b[38;5;241m.\u001b[39mpredict(X_test)),\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m\"\u001b[39m: accuracy_score(y_test, log_model\u001b[38;5;241m.\u001b[39mpredict(X_test)),\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscv_RBF_model\u001b[39m\u001b[38;5;124m\"\u001b[39m: accuracy_score(y_test, scv_RBF_model\u001b[38;5;241m.\u001b[39mpredict(X_test)),\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKNN_model\u001b[39m\u001b[38;5;124m\"\u001b[39m: accuracy_score(y_test, knn_model\u001b[38;5;241m.\u001b[39mpredict(X_test)),\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecision Tree\u001b[39m\u001b[38;5;124m\"\u001b[39m: accuracy_score(y_test, dt_model\u001b[38;5;241m.\u001b[39mpredict(X_test)),\n\u001b[0;32m      8\u001b[0m }\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "accuracies = {\n",
    "    \"SVC_liner\": accuracy_score(y_test, scv_lr_model.predict(X_test)),\n",
    "    \"Random Forest\": accuracy_score(y_test, rf_model.predict(X_test)),\n",
    "    \"Logistic Regression\": accuracy_score(y_test, log_model.predict(X_test)),\n",
    "    \"scv_RBF_model\": accuracy_score(y_test, scv_RBF_model.predict(X_test)),\n",
    "    \"KNN_model\": accuracy_score(y_test, knn_model.predict(X_test)),\n",
    "    \"Decision Tree\": accuracy_score(y_test, dt_model.predict(X_test)),\n",
    "}\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.bar(accuracies.keys(), accuracies.values(), color='skyblue')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"모델별 정확도 비교\")\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
